{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmV0J2Ly3WTn",
        "outputId": "1b7f372f-58da-4c86-eeb9-462cba0c1586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting madgrad\n",
            "  Downloading madgrad-1.3.tar.gz (7.9 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: madgrad\n",
            "  Building wheel for madgrad (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for madgrad: filename=madgrad-1.3-py3-none-any.whl size=11868 sha256=1fa595241611fe4d089094055a5ef60b2bbfe568a52279e39ceddc6f4a0b0823\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/a3/83/7ed1ddc517cd87cad4e3a4aec7f8ea1d5e83a5ff282e51490a\n",
            "Successfully built madgrad\n",
            "Installing collected packages: madgrad\n",
            "Successfully installed madgrad-1.3\n"
          ]
        }
      ],
      "source": [
        "!pip install madgrad"
      ],
      "id": "bmV0J2Ly3WTn"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plUo4wG-3q_3",
        "outputId": "a54665a5-bb6d-411e-eb75-d52e24fc6c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m122.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.1\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers"
      ],
      "id": "plUo4wG-3q_3"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGcJiO_Q6S7D",
        "outputId": "de047dbe-a1a6-4bd4-dc52-aaeb5f0087da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "fGcJiO_Q6S7D"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMysk7OX6gSd",
        "outputId": "a4e6eee8-35e8-4769-da0d-262fee5c8833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'gdrive/MyDrive'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd gdrive/MyDrive"
      ],
      "id": "cMysk7OX6gSd"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "coupled-inflation"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from collections import Counter\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "from madgrad import MADGRAD\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score\n",
        "\n",
        "import pickle\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import copy\n",
        "\n",
        "import transformers\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModel,\n",
        "    AutoTokenizer,\n",
        "    MMBTConfig,\n",
        "    MMBTModel,\n",
        "    MMBTForClassification,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")"
      ],
      "id": "coupled-inflation"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "LvFUzR_H7DhQ",
        "outputId": "46fc22a8-fbb8-435b-868a-55d02282d4d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=92b8b32daea8775f7499fb120c3feca040964920fde0c546965efe523e87a645\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.25.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "! pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "id": "LvFUzR_H7DhQ"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsbNm8cT7Ka4",
        "outputId": "104a097b-a1d0-418e-b941-d3c6b2f89c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_PROJECT=hateful_memes_mmbt_vit\n"
          ]
        }
      ],
      "source": [
        "%env WANDB_PROJECT=hateful_memes_mmbt_vit"
      ],
      "id": "FsbNm8cT7Ka4"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neural-stadium",
        "outputId": "d795a5d2-8aac-4e55-cd9c-e0d9bf213c2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "id": "neural-stadium"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "common-arabic"
      },
      "outputs": [],
      "source": [
        "num_image_embeds = 4\n",
        "num_labels = 1\n",
        "gradient_accumulation_steps = 20\n",
        "data_dir = './hateful_memes'\n",
        "max_seq_length = 80 \n",
        "max_grad_norm = 0.5\n",
        "train_batch_size = 16\n",
        "eval_batch_size = 16\n",
        "# image_encoder_size = 288\n",
        "# image_features_size = 640\n",
        "num_train_epochs = 10"
      ],
      "id": "common-arabic"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "framed-rings"
      },
      "source": [
        "Image encoder using vit\n"
      ],
      "id": "framed-rings"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "practical-lyric"
      },
      "outputs": [],
      "source": [
        "POOLING_BREAKDOWN = {1: (1, 1), 2: (2, 1), 3: (3, 1), 4: (2, 2), 5: (5, 1), 6: (3, 2), 7: (7, 1), 8: (4, 2), 9: (3, 3)}\n",
        "\n",
        "from transformers import ViTFeatureExtractor\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self, num_image_embeds):\n",
        "        super().__init__()\n",
        "        # model = torchvision.models.vit_b_16(pretrained=True)\n",
        "        # modules = list(model.children())[:-2]\n",
        "        # self.model = nn.Sequential(*modules)\n",
        "        # self.pool = nn.AdaptiveAvgPool2d(POOLING_BREAKDOWN[num_image_embeds])\n",
        "\n",
        "        model_name_or_path = 'google/vit-base-patch16-224-in21k'\n",
        "        feature_extractor = ViTFeatureExtractor.from_pretrained(model_name_or_path)\n",
        "        self.model = feature_extractor\n",
        "\n",
        "    def forward(self, x):\n",
        "        # out = self.pool(self.model(x))\n",
        "        # out = torch.flatten(out, start_dim=2)\n",
        "        # out = out.transpose(1, 2).contiguous()\n",
        "        # print(out)\n",
        "        # return out\n",
        "        return self.model(x)"
      ],
      "id": "practical-lyric"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "blind-terrorism"
      },
      "outputs": [],
      "source": [
        "class JsonlDataset(Dataset):\n",
        "    def __init__(self, data_path, tokenizer, transforms, max_seq_length):\n",
        "        self.data = [json.loads(l) for l in open(data_path)]\n",
        "        self.data_dir = os.path.dirname(data_path)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence = torch.LongTensor(self.tokenizer.encode(self.data[index][\"text\"], add_special_tokens=True))\n",
        "        start_token, sentence, end_token = sentence[0], sentence[1:-1], sentence[-1]\n",
        "        sentence = sentence[:self.max_seq_length]\n",
        "\n",
        "        label = torch.FloatTensor([self.data[index][\"label\"]])\n",
        "\n",
        "        image = Image.open(os.path.join(self.data_dir, self.data[index][\"img\"])).convert(\"RGB\")\n",
        "        image = self.transforms(image)\n",
        "        image.to(device)\n",
        "\n",
        "        return {\n",
        "            \"image_start_token\": start_token,            \n",
        "            \"image_end_token\": end_token,\n",
        "            \"sentence\": sentence,\n",
        "            \"image\": image,\n",
        "            \"label\": label            \n",
        "        }\n",
        "\n",
        "    def get_label_frequencies(self):\n",
        "        label_freqs = Counter()\n",
        "        for row in self.data:\n",
        "            label_freqs.update([row[\"label\"]])\n",
        "        return label_freqs\n",
        "    \n",
        "    def get_labels(self):\n",
        "        labels = []\n",
        "        for row in self.data:\n",
        "            labels.append(row[\"label\"])\n",
        "        return labels"
      ],
      "id": "blind-terrorism"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "restricted-portsmouth"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    lens = [len(row[\"sentence\"]) for row in batch]\n",
        "    bsz, max_seq_len = len(batch), max(lens)\n",
        "\n",
        "    mask_tensor = torch.zeros(bsz, max_seq_len, dtype=torch.long)\n",
        "    text_tensor = torch.zeros(bsz, max_seq_len, dtype=torch.long)\n",
        "\n",
        "    for i_batch, (input_row, length) in enumerate(zip(batch, lens)):\n",
        "        text_tensor[i_batch, :length] = input_row[\"sentence\"]\n",
        "        mask_tensor[i_batch, :length] = 1\n",
        "    \n",
        "    img_tensor = torch.stack([row[\"image\"] for row in batch])\n",
        "    tgt_tensor = torch.stack([row[\"label\"] for row in batch])\n",
        "    img_start_token = torch.stack([row[\"image_start_token\"] for row in batch])\n",
        "    img_end_token = torch.stack([row[\"image_end_token\"] for row in batch])\n",
        "\n",
        "    return text_tensor, mask_tensor, img_tensor, img_start_token, img_end_token, tgt_tensor"
      ],
      "id": "restricted-portsmouth"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_transforms():\n",
        "    return transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(\n",
        "                mean=[0.46777044, 0.44531429, 0.40661017],\n",
        "                std=[0.12221994, 0.12145835, 0.14380469],\n",
        "            ),\n",
        "        ]\n",
        "    )"
      ],
      "metadata": {
        "id": "fk2nBB4GcI7I"
      },
      "id": "fk2nBB4GcI7I",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "valuable-hindu"
      },
      "outputs": [],
      "source": [
        "def load_examples(tokenizer, evaluate=False):\n",
        "    # path = os.path.join(data_dir, \"dev_seen_clean.jsonl\" if evaluate else f\"train_augmented.jsonl\")\n",
        "    path = os.path.join(data_dir, \"dev_seen.jsonl\" if evaluate else f\"train.jsonl\")\n",
        "    transforms = get_image_transforms()\n",
        "    dataset = JsonlDataset(path, tokenizer, transforms, max_seq_length - num_image_embeds - 2)\n",
        "    return dataset"
      ],
      "id": "valuable-hindu"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "offshore-corner"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(save_path, model, valid_loss):\n",
        "\n",
        "    if save_path == None:\n",
        "        return\n",
        "    \n",
        "    state_dict = {'model_state_dict': model.state_dict(),\n",
        "                  'valid_loss': valid_loss}\n",
        "    \n",
        "    torch.save(state_dict, save_path)\n",
        "    print(f'Model saved to ==> {save_path}')\n",
        "    \n",
        "def load_checkpoint(load_path, model):\n",
        "    \n",
        "    if load_path==None:\n",
        "        return\n",
        "    \n",
        "    state_dict = torch.load(load_path, map_location=device)\n",
        "    print(f'Model loaded from <== {load_path}')\n",
        "    \n",
        "    model.load_state_dict(state_dict['model_state_dict'])\n",
        "    return state_dict['valid_loss']"
      ],
      "id": "offshore-corner"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "89385041f59b4669a3ace8d7886a9086",
            "c5f220b9dcdd4bcd94a1a03785662105",
            "8a75f878db574557ac9ec3adf318d407",
            "3c08f6ea2e584848a47e0a2950d7715c",
            "751d09f687aa43aea16074a50ec02304",
            "04e73c3aaef24e33ac38a46ae05f786c",
            "d3d2a0c11fe34127970b8a647446f5ca",
            "cc4fcdb4570b481e9b27e084824ddb91",
            "51efd21416f74b279fbab6c6784809f7",
            "5c979a01c3e64f3fa497a3478f79f812",
            "bd0175cc26ea4c8fb7eeb86e0de80f9a"
          ]
        },
        "id": "conservative-priest",
        "outputId": "c4636e2c-1023-4253-8547-3bd361db1f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Hate-speech-CNERG/bert-base-uncased-hatexplain were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)rocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89385041f59b4669a3ace8d7886a9086"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = 'Hate-speech-CNERG/bert-base-uncased-hatexplain'\n",
        "transformer_config = AutoConfig.from_pretrained(model_name) \n",
        "transformer = AutoModel.from_pretrained(model_name, config=transformer_config)\n",
        "img_encoder = ImageEncoder(num_image_embeds)"
      ],
      "id": "conservative-priest"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "periodic-prime"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True)"
      ],
      "id": "periodic-prime"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "compact-excellence"
      },
      "outputs": [],
      "source": [
        "config = MMBTConfig(transformer_config, num_labels=num_labels)\n",
        "model = MMBTForClassification(config, transformer, img_encoder)"
      ],
      "id": "compact-excellence"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "secure-executive"
      },
      "outputs": [],
      "source": [
        "model.to(device);"
      ],
      "id": "secure-executive"
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfp0uXGBKcEr",
        "outputId": "b7172d5e-ed2a-4f92-cd0a-52af8573728c"
      },
      "id": "Kfp0uXGBKcEr",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive'\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "future-sport"
      },
      "outputs": [],
      "source": [
        "train_dataset = load_examples(tokenizer, evaluate=False)\n",
        "eval_dataset = load_examples(tokenizer, evaluate=True)   \n",
        "\n",
        "train_sampler = RandomSampler(train_dataset)\n",
        "eval_sampler = SequentialSampler(eval_dataset)\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        sampler=train_sampler,\n",
        "        batch_size=train_batch_size,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "        eval_dataset, \n",
        "        sampler=eval_sampler, \n",
        "        batch_size=eval_batch_size, \n",
        "        collate_fn=collate_fn\n",
        "    )"
      ],
      "id": "future-sport"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "collective-blogger"
      },
      "outputs": [],
      "source": [
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = [\"bias\", \n",
        "            \"LayerNorm.weight\"\n",
        "           ]\n",
        "weight_decay = 0.0005\n",
        "\n",
        "optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "t_total = (len(train_dataloader) // gradient_accumulation_steps) * num_train_epochs\n",
        "warmup_steps = t_total // 10\n",
        "\n",
        "optimizer = MADGRAD(optimizer_grouped_parameters, lr=2e-4)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, warmup_steps, t_total\n",
        "    )\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "id": "collective-blogger"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "pending-advocacy"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, tokenizer, criterion, dataloader, tres = 0.5): \n",
        "    \n",
        "    # Eval!\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = None\n",
        "    proba = None\n",
        "    out_label_ids = None\n",
        "    for batch in dataloader:\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        with torch.no_grad():\n",
        "            labels = batch[5]\n",
        "            inputs = {\n",
        "                \"input_ids\": batch[0],\n",
        "                \"input_modal\": batch[2],\n",
        "                \"attention_mask\": batch[1],\n",
        "                \"modal_start_tokens\": batch[3],\n",
        "                \"modal_end_tokens\": batch[4],\n",
        "                \"return_dict\": False\n",
        "            }\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "            tmp_eval_loss = criterion(logits, labels)\n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "        if preds is None:\n",
        "            preds = torch.sigmoid(logits).detach().cpu().numpy() > tres\n",
        "            proba = torch.sigmoid(logits).detach().cpu().numpy()\n",
        "            out_label_ids = labels.detach().cpu().numpy()\n",
        "        else:            \n",
        "            preds = np.append(preds, torch.sigmoid(logits).detach().cpu().numpy() > tres, axis=0)\n",
        "            proba = np.append(proba, torch.sigmoid(logits).detach().cpu().numpy(), axis=0)\n",
        "            out_label_ids = np.append(out_label_ids, labels.detach().cpu().numpy(), axis=0)\n",
        "    \n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "\n",
        "    result = {\n",
        "        \"loss\": eval_loss,\n",
        "        \"accuracy\": accuracy_score(out_label_ids, preds),\n",
        "        \"AUC\": roc_auc_score(out_label_ids, proba),\n",
        "        \"micro_f1\": f1_score(out_label_ids, preds, average=\"micro\"),\n",
        "        \"prediction\": preds,\n",
        "        \"labels\": out_label_ids,\n",
        "        \"proba\": proba\n",
        "    }\n",
        "    \n",
        "    return result"
      ],
      "id": "pending-advocacy"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "f977452732ac4f489d7e45a587aa3966",
            "832ba24c58e7463e88b8375f8840d625",
            "ecdfdb83f953464b9bbddd4f0cc915cd",
            "283c07f80a8a4d3682d12ef3d5f88fc1",
            "b1afb1b99424442f91ff17d0bef22a68",
            "445762fa1f7c492badb63b564ea07528",
            "323d009d82324a84b701bd0b96307cb0",
            "ee3f0bb3549d4416bb5b6f25ed7c4cf6"
          ]
        },
        "id": "m_d4yn0g8ozr",
        "outputId": "31cda839-68ec-41e7-955c-200eb9dd0416"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:1dccju6n) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f977452732ac4f489d7e45a587aa3966"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">restful-shape-1</strong> at: <a href='https://wandb.ai/emilycs229/hateful_memes_mmbt_vit/runs/1dccju6n' target=\"_blank\">https://wandb.ai/emilycs229/hateful_memes_mmbt_vit/runs/1dccju6n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230612_055306-1dccju6n/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:1dccju6n). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/wandb/run-20230612_062745-bu9lfiw0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/emilycs229/hateful_memes_mmbt_vit/runs/bu9lfiw0' target=\"_blank\">happy-plasma-2</a></strong> to <a href='https://wandb.ai/emilycs229/hateful_memes_mmbt_vit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/emilycs229/hateful_memes_mmbt_vit' target=\"_blank\">https://wandb.ai/emilycs229/hateful_memes_mmbt_vit</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/emilycs229/hateful_memes_mmbt_vit/runs/bu9lfiw0' target=\"_blank\">https://wandb.ai/emilycs229/hateful_memes_mmbt_vit/runs/bu9lfiw0</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    # Track hyperparameters and run metadata\n",
        "    project=\"hateful_memes_mmbt_vit\"\n",
        "    )"
      ],
      "id": "m_d4yn0g8ozr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "continuous-asbestos"
      },
      "outputs": [],
      "source": [
        "optimizer_step = 0\n",
        "global_step = 0\n",
        "train_step = 0\n",
        "tr_loss, logging_loss = 0.0, 0.0\n",
        "best_valid_auc = 0.75\n",
        "global_steps_list = []\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "val_acc_list = []\n",
        "val_auc_list = []\n",
        "eval_every = len(train_dataloader) // 7\n",
        "running_loss = 0\n",
        "file_path=\"models/\"\n",
        "\n",
        "model.zero_grad()\n",
        "\n",
        "for i in range(num_train_epochs):\n",
        "    print(\"Epoch\", i+1, f\"from {num_train_epochs}\")\n",
        "    whole_y_pred=np.array([])\n",
        "    whole_y_t=np.array([])\n",
        "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "        model.train()\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        labels = batch[5]\n",
        "        inputs = {\n",
        "            \"input_ids\": batch[0],\n",
        "            \"input_modal\": batch[2],\n",
        "            \"attention_mask\": batch[1],\n",
        "            \"modal_start_tokens\": batch[3],\n",
        "            \"modal_end_tokens\": batch[4],\n",
        "            \"return_dict\": False\n",
        "        }\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "        loss = criterion(logits, labels)        \n",
        "        \n",
        "        if gradient_accumulation_steps > 1:\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "            \n",
        "        loss.backward()\n",
        "        \n",
        "        tr_loss += loss.item()\n",
        "        running_loss += loss.item()\n",
        "        global_step += 1\n",
        "        \n",
        "        if (step + 1) % gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "            scheduler.step()  # Update learning rate schedule         \n",
        "            \n",
        "            optimizer_step += 1\n",
        "            optimizer.zero_grad()   \n",
        "                        \n",
        "        if (step + 1) % eval_every == 0:\n",
        "            \n",
        "            average_train_loss = running_loss / eval_every\n",
        "            train_loss_list.append(average_train_loss)\n",
        "            global_steps_list.append(global_step)\n",
        "            running_loss = 0.0  \n",
        "            \n",
        "            val_result = evaluate(model, tokenizer, criterion, eval_dataloader)\n",
        "            wandb.log(val_result)\n",
        "            val_loss_list.append(val_result['loss'])\n",
        "            val_acc_list.append(val_result['accuracy'])\n",
        "            val_auc_list.append(val_result['AUC'])\n",
        "            \n",
        "            # checkpoint\n",
        "            if val_result['AUC'] > best_valid_auc:\n",
        "                best_valid_auc = val_result['AUC']\n",
        "                val_loss = val_result['loss']\n",
        "                val_acc = val_result['accuracy']\n",
        "                model_path = f'{file_path}/model-embs{num_image_embeds}-seq{max_seq_length}-auc{best_valid_auc:.3f}-loss{val_loss:.3f}-acc{val_acc:.3f}.pt'\n",
        "                print(f\"AUC improved, so saving this model\")  \n",
        "                save_checkpoint(model_path, model, val_result['loss'])              \n",
        "            \n",
        "            print(\"Train loss:\", f\"{average_train_loss:.4f}\", \n",
        "                  \"Val loss:\", f\"{val_result['loss']:.4f}\",\n",
        "                  \"Val acc:\", f\"{val_result['accuracy']:.4f}\",\n",
        "                  \"AUC:\", f\"{val_result['AUC']:.4f}\")   \n",
        "    print('\\n')"
      ],
      "id": "continuous-asbestos"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89385041f59b4669a3ace8d7886a9086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5f220b9dcdd4bcd94a1a03785662105",
              "IPY_MODEL_8a75f878db574557ac9ec3adf318d407",
              "IPY_MODEL_3c08f6ea2e584848a47e0a2950d7715c"
            ],
            "layout": "IPY_MODEL_751d09f687aa43aea16074a50ec02304"
          }
        },
        "c5f220b9dcdd4bcd94a1a03785662105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04e73c3aaef24e33ac38a46ae05f786c",
            "placeholder": "​",
            "style": "IPY_MODEL_d3d2a0c11fe34127970b8a647446f5ca",
            "value": "Downloading (…)rocessor_config.json: 100%"
          }
        },
        "8a75f878db574557ac9ec3adf318d407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc4fcdb4570b481e9b27e084824ddb91",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51efd21416f74b279fbab6c6784809f7",
            "value": 160
          }
        },
        "3c08f6ea2e584848a47e0a2950d7715c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c979a01c3e64f3fa497a3478f79f812",
            "placeholder": "​",
            "style": "IPY_MODEL_bd0175cc26ea4c8fb7eeb86e0de80f9a",
            "value": " 160/160 [00:00&lt;00:00, 12.9kB/s]"
          }
        },
        "751d09f687aa43aea16074a50ec02304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04e73c3aaef24e33ac38a46ae05f786c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3d2a0c11fe34127970b8a647446f5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc4fcdb4570b481e9b27e084824ddb91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51efd21416f74b279fbab6c6784809f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c979a01c3e64f3fa497a3478f79f812": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0175cc26ea4c8fb7eeb86e0de80f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f977452732ac4f489d7e45a587aa3966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_832ba24c58e7463e88b8375f8840d625",
              "IPY_MODEL_ecdfdb83f953464b9bbddd4f0cc915cd"
            ],
            "layout": "IPY_MODEL_283c07f80a8a4d3682d12ef3d5f88fc1"
          }
        },
        "832ba24c58e7463e88b8375f8840d625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1afb1b99424442f91ff17d0bef22a68",
            "placeholder": "​",
            "style": "IPY_MODEL_445762fa1f7c492badb63b564ea07528",
            "value": "0.012 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "ecdfdb83f953464b9bbddd4f0cc915cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_323d009d82324a84b701bd0b96307cb0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee3f0bb3549d4416bb5b6f25ed7c4cf6",
            "value": 1
          }
        },
        "283c07f80a8a4d3682d12ef3d5f88fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1afb1b99424442f91ff17d0bef22a68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "445762fa1f7c492badb63b564ea07528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "323d009d82324a84b701bd0b96307cb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee3f0bb3549d4416bb5b6f25ed7c4cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}